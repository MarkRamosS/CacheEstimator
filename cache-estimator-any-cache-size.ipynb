{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "604ec1ed",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-14T15:30:54.873097Z",
     "iopub.status.busy": "2023-12-14T15:30:54.872765Z",
     "iopub.status.idle": "2023-12-14T15:31:19.962888Z",
     "shell.execute_reply": "2023-12-14T15:31:19.962089Z"
    },
    "papermill": {
     "duration": 25.102848,
     "end_time": "2023-12-14T15:31:19.965025",
     "exception": false,
     "start_time": "2023-12-14T15:30:54.862177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, LSTM, Attention, Conv1D, Conv2D\n",
    "from keras.metrics import MeanSquaredError\n",
    "from keras.losses import MeanSquaredError\n",
    "import keras\n",
    "from scipy.stats.mstats import gmean\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d81bd2",
   "metadata": {
    "papermill": {
     "duration": 0.00849,
     "end_time": "2023-12-14T15:31:19.982809",
     "exception": false,
     "start_time": "2023-12-14T15:31:19.974319",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Weights, for the weighted prediction later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ca96891",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T15:31:20.001942Z",
     "iopub.status.busy": "2023-12-14T15:31:20.001343Z",
     "iopub.status.idle": "2023-12-14T15:31:20.014652Z",
     "shell.execute_reply": "2023-12-14T15:31:20.013730Z"
    },
    "papermill": {
     "duration": 0.025173,
     "end_time": "2023-12-14T15:31:20.016650",
     "exception": false,
     "start_time": "2023-12-14T15:31:19.991477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights = json.load(open('/kaggle/input/cache-estimator-data/out_weights.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6809614e",
   "metadata": {
    "papermill": {
     "duration": 0.00918,
     "end_time": "2023-12-14T15:31:20.034913",
     "exception": false,
     "start_time": "2023-12-14T15:31:20.025733",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Read the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cb668b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T15:31:20.055075Z",
     "iopub.status.busy": "2023-12-14T15:31:20.054448Z",
     "iopub.status.idle": "2023-12-14T15:31:21.463861Z",
     "shell.execute_reply": "2023-12-14T15:31:21.462841Z"
    },
    "papermill": {
     "duration": 1.421519,
     "end_time": "2023-12-14T15:31:21.465876",
     "exception": false,
     "start_time": "2023-12-14T15:31:20.044357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6163, 900) (6163, 8)\n"
     ]
    }
   ],
   "source": [
    "def read_df(path, embeddings_path=None):\n",
    "    # Read csv\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    # Append filename and source_file column column\n",
    "    filenames = []\n",
    "    for i in df[\"id\"]:\n",
    "        nmb = i.split('_')[-1]\n",
    "        filenames.append(i[:-len(nmb)-1])\n",
    "    df[\"file_name\"] = filenames\n",
    "    filenames = list(set(filenames))\n",
    "    df['source_file'] = df[\"file_name\"].apply(lambda x: int(x[:3]))\n",
    "    # Append embeddings\n",
    "    if embeddings_path != None:\n",
    "        embedding_df = pd.read_csv(embeddings_path)\n",
    "        embedding_df['source_file'] = embedding_df['fname']\n",
    "        embedding_df['embeddings'] = embedding_df['embeddings'].apply(lambda x: np.array([*map(float, x.strip('][').replace(\"'\",\"\").split(','))]))\n",
    "        df = pd.merge(df, embedding_df).drop(columns=[\"fname\"])\n",
    "    # Calculate miss ratios into a seperate dataframe\n",
    "    miss_ratios = pd.DataFrame()\n",
    "    for i in [\"768\", \"1024\", \"1536\", \"2048\", \"3072\",\"4096\", \"6144\", \"8192\"]:\n",
    "        miss_ratios[i] = df['misses_'+i] / df['accesses_'+i]\n",
    "        df = df.drop(columns=['misses_'+i, 'accesses_'+i])\n",
    "        if 'l1d_accesses_'+i in df.columns:\n",
    "            df = df.drop(columns=['l1d_accesses_'+i])\n",
    "    return df, miss_ratios\n",
    "rds, mrs = read_df('/kaggle/input/cache-estimator-data/dataset_lru_extra.csv', '/kaggle/input/cache-estimator-data/embeddings/flow-aware-f.csv')\n",
    "print(rds.shape, mrs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12cd6aff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T15:31:21.485390Z",
     "iopub.status.busy": "2023-12-14T15:31:21.484588Z",
     "iopub.status.idle": "2023-12-14T15:31:21.519499Z",
     "shell.execute_reply": "2023-12-14T15:31:21.518600Z"
    },
    "papermill": {
     "duration": 0.046649,
     "end_time": "2023-12-14T15:31:21.521520",
     "exception": false,
     "start_time": "2023-12-14T15:31:21.474871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                0           1           2          3          4          5  \\\n",
       "0     50816880.0  17323312.0  11868112.0  7701840.0  3853504.0  5287776.0   \n",
       "1     17361520.0   6023600.0   4203744.0  2591488.0  1828656.0  1847648.0   \n",
       "2     58283520.0  17249296.0  14592592.0  9466576.0  7204896.0  5614336.0   \n",
       "3      3098304.0   3037808.0   2698720.0  2692176.0  1999568.0  1238496.0   \n",
       "4      1623056.0   1618144.0   1501200.0  1353728.0  1014736.0   670656.0   \n",
       "...          ...         ...         ...        ...        ...        ...   \n",
       "6158   4869744.0   5968224.0   3301024.0  2821488.0  2218352.0  1938048.0   \n",
       "6159   4967104.0   7056944.0   3530208.0  2928336.0  2367040.0  2018816.0   \n",
       "6160  18063488.0  19199008.0   9437200.0  7269680.0  7833904.0  3198400.0   \n",
       "6161  13498912.0  14343616.0   6633152.0  5098416.0  6450640.0  2275728.0   \n",
       "6162  26404208.0  36893024.0  10084752.0  2060848.0  2511312.0  1297024.0   \n",
       "\n",
       "              6          7          8          9  ...  3892314112  3959422976  \\\n",
       "0     7547888.0  4450480.0  4572784.0  4012032.0  ...         0.0         0.0   \n",
       "1     2429008.0  1860832.0  1582208.0  1378080.0  ...         0.0         0.0   \n",
       "2     8940048.0  4846496.0  5377296.0  3936432.0  ...         0.0         0.0   \n",
       "3      939408.0   815232.0   694672.0   587600.0  ...         0.0         0.0   \n",
       "4      500784.0   432384.0   374944.0   305328.0  ...         0.0         0.0   \n",
       "...         ...        ...        ...        ...  ...         ...         ...   \n",
       "6158  1205216.0  1027344.0   888272.0   643616.0  ...         0.0         0.0   \n",
       "6159  1157072.0   981616.0   821872.0   608576.0  ...         0.0         0.0   \n",
       "6160  3376912.0  1776144.0  1934080.0  1485120.0  ...         0.0         0.0   \n",
       "6161  2397248.0  1270496.0  1381904.0  1165088.0  ...         0.0         0.0   \n",
       "6162   890224.0   772176.0   558336.0        0.0  ...         0.0         0.0   \n",
       "\n",
       "      4026531840  4093640704  4160749568  4227858432                     id  \\\n",
       "0            0.0         0.0         0.0         0.0    400.perlbench-41B_0   \n",
       "1            0.0         0.0         0.0         0.0  400.perlbench-41B_436   \n",
       "2            0.0         0.0         0.0         0.0    400.perlbench-50B_0   \n",
       "3            0.0         0.0         0.0         0.0       401.bzip2-226B_0   \n",
       "4            0.0         0.0         0.0         0.0      401.bzip2-226B_54   \n",
       "...          ...         ...         ...         ...                    ...   \n",
       "6158         0.0         0.0         0.0         0.0     657.xz_s-3167B_466   \n",
       "6159         0.0         0.0         0.0         0.0     657.xz_s-3167B_574   \n",
       "6160         0.0         0.0         0.0         0.0       657.xz_s-4994B_0   \n",
       "6161         0.0         0.0         0.0         0.0     657.xz_s-4994B_343   \n",
       "6162         0.0         0.0         0.0         0.0         657.xz_s-56B_0   \n",
       "\n",
       "              file_name  source_file  \\\n",
       "0     400.perlbench-41B          400   \n",
       "1     400.perlbench-41B          400   \n",
       "2     400.perlbench-50B          400   \n",
       "3        401.bzip2-226B          401   \n",
       "4        401.bzip2-226B          401   \n",
       "...                 ...          ...   \n",
       "6158     657.xz_s-3167B          657   \n",
       "6159     657.xz_s-3167B          657   \n",
       "6160     657.xz_s-4994B          657   \n",
       "6161     657.xz_s-4994B          657   \n",
       "6162       657.xz_s-56B          657   \n",
       "\n",
       "                                             embeddings  \n",
       "0     [-11.067213, 7.318718, 84.079863, 54.580061, -...  \n",
       "1     [-11.067213, 7.318718, 84.079863, 54.580061, -...  \n",
       "2     [-11.067213, 7.318718, 84.079863, 54.580061, -...  \n",
       "3     [-0.585071, 9.35283, 41.856682, 22.22657, -20....  \n",
       "4     [-0.585071, 9.35283, 41.856682, 22.22657, -20....  \n",
       "...                                                 ...  \n",
       "6158  [-1.143718, 15.872542, 102.671806, 51.022815, ...  \n",
       "6159  [-1.143718, 15.872542, 102.671806, 51.022815, ...  \n",
       "6160  [-1.143718, 15.872542, 102.671806, 51.022815, ...  \n",
       "6161  [-1.143718, 15.872542, 102.671806, 51.022815, ...  \n",
       "6162  [-1.143718, 15.872542, 102.671806, 51.022815, ...  \n",
       "\n",
       "[6163 rows x 900 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rds.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb689b2",
   "metadata": {
    "papermill": {
     "duration": 0.008936,
     "end_time": "2023-12-14T15:31:21.539666",
     "exception": false,
     "start_time": "2023-12-14T15:31:21.530730",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train-Test split\n",
    "Here we split the data into training and testing set. \n",
    "\n",
    "The train_test_split method is for the one model, where we separate some columns and try to predict them based on the others.\n",
    "\n",
    "The train_test_split_sec method separates all data for the test_bench benchmark and moves it to the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01ce8524",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T15:31:21.559352Z",
     "iopub.status.busy": "2023-12-14T15:31:21.559033Z",
     "iopub.status.idle": "2023-12-14T15:31:22.492549Z",
     "shell.execute_reply": "2023-12-14T15:31:22.491480Z"
    },
    "papermill": {
     "duration": 0.945662,
     "end_time": "2023-12-14T15:31:22.494805",
     "exception": false,
     "start_time": "2023-12-14T15:31:21.549143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6163, 898) (6163, 1) (43141, 898) (43141, 1) (43141, 4)\n"
     ]
    }
   ],
   "source": [
    "test_ids = pd.DataFrame()\n",
    "extra_df = []\n",
    "def train_test_split(df, miss_ratios):\n",
    "    global test_ids, extra_df\n",
    "    train_rds = pd.DataFrame()\n",
    "    train_mrs = pd.DataFrame()\n",
    "    test_rds  = pd.DataFrame()\n",
    "    test_mrs  = pd.DataFrame()\n",
    "    train_cols = ['2048']\n",
    "    test_cols = ['768', '1024', '1536', '3072', '4096', '6144', '8192']\n",
    "    for i in train_cols:\n",
    "        tmp_df = df.copy()\n",
    "        tmp_df['column'] = float(i)\n",
    "        train_rds = pd.concat([train_rds, tmp_df], ignore_index=True)\n",
    "        new_tmp_df = miss_ratios[i]\n",
    "        train_mrs = pd.concat([train_mrs, new_tmp_df], ignore_index=True)\n",
    "    \n",
    "    for test_col in test_cols:\n",
    "        tmp_df = df.copy()\n",
    "        tmp_df['column'] = float(test_col)\n",
    "        test_rds = pd.concat([test_rds, tmp_df], ignore_index=True)\n",
    "        new_tmp_df = miss_ratios[test_col]\n",
    "        test_mrs = pd.concat([test_mrs, new_tmp_df], ignore_index=True)\n",
    "    test_ids = test_rds[[\"id\", \"file_name\", \"source_file\", \"column\"]]\n",
    "        \n",
    "    test_ids.to_csv(f'/kaggle/working/id_col_lru_other_4.csv')\n",
    "\n",
    "    train_rds = train_rds.drop(columns=[\"id\", \"file_name\", \"source_file\"])\n",
    "    test_rds = test_rds.drop(columns=[\"id\", \"file_name\", \"source_file\"])\n",
    "    return train_rds, train_mrs, test_rds, test_mrs\n",
    "\n",
    "train_rds, train_mrs, test_rds, test_mrs  = train_test_split(rds, mrs)\n",
    "print(train_rds.shape, train_mrs.shape, test_rds.shape, test_mrs.shape, test_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a578794",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T15:31:22.515410Z",
     "iopub.status.busy": "2023-12-14T15:31:22.515098Z",
     "iopub.status.idle": "2023-12-14T15:31:22.621145Z",
     "shell.execute_reply": "2023-12-14T15:31:22.620127Z"
    },
    "papermill": {
     "duration": 0.118137,
     "end_time": "2023-12-14T15:31:22.623227",
     "exception": false,
     "start_time": "2023-12-14T15:31:22.505090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6160, 898) (6160, 1) (24, 898) (24, 1) (24, 4) (24, 1)\n"
     ]
    }
   ],
   "source": [
    "test_ids = pd.DataFrame()\n",
    "test_outputs = pd.DataFrame()\n",
    "def train_test_split_sec(df, miss_ratios, test_bench):\n",
    "    global test_ids, test_outputs\n",
    "    train_rds = pd.DataFrame()\n",
    "    train_mrs = pd.DataFrame()\n",
    "    test_rds  = pd.DataFrame()\n",
    "    test_mrs  = pd.DataFrame()\n",
    "    train_cols = ['8192']\n",
    "    test_cols = ['768', '1024', '1536', '2048', '3072', '4096', '6144', '8192']\n",
    "    for i in train_cols:\n",
    "        tmp_df = df[~df['source_file'].isin(test_bench)].copy()\n",
    "        tmp_df['column'] = float(i)\n",
    "        train_rds = pd.concat([train_rds, tmp_df], ignore_index=True)\n",
    "        new_tmp_df = miss_ratios[~df['source_file'].isin(test_bench)][i]\n",
    "        train_mrs = pd.concat([train_mrs, new_tmp_df], ignore_index=True)\n",
    "    \n",
    "    for test_col in test_cols:\n",
    "        tmp_df = df[df['source_file'].isin(test_bench)].copy()\n",
    "        tmp_df['column'] = float(test_col)\n",
    "        test_rds = pd.concat([test_rds, tmp_df], ignore_index=True)\n",
    "        new_tmp_df = miss_ratios[df['source_file'].isin(test_bench)][test_col]\n",
    "        test_mrs = pd.concat([test_mrs, new_tmp_df], ignore_index=True)\n",
    "    tmp_ids = test_rds[[\"id\", \"file_name\", \"source_file\", \"column\"]]\n",
    "    test_ids = pd.concat([test_ids, tmp_ids], ignore_index=True)\n",
    "#     test_ids.to_csv(f'/kaggle/working/id_col_lru_other_6b.csv')\n",
    "    test_outputs = pd.concat([test_outputs, test_mrs], ignore_index=True)\n",
    "    train_rds = train_rds.drop(columns=[\"id\", \"file_name\", \"source_file\"])\n",
    "    test_rds = test_rds.drop(columns=[\"id\", \"file_name\", \"source_file\"])\n",
    "    return train_rds, train_mrs, test_rds, test_mrs\n",
    "\n",
    "train_rds, train_mrs, test_rds, test_mrs  = train_test_split_sec(rds, mrs, [400])\n",
    "print(train_rds.shape, train_mrs.shape, test_rds.shape, test_mrs.shape, test_ids.shape, test_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ebb3fba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T15:31:22.643128Z",
     "iopub.status.busy": "2023-12-14T15:31:22.642828Z",
     "iopub.status.idle": "2023-12-14T15:31:25.004196Z",
     "shell.execute_reply": "2023-12-14T15:31:25.003193Z"
    },
    "papermill": {
     "duration": 2.37408,
     "end_time": "2023-12-14T15:31:25.006814",
     "exception": false,
     "start_time": "2023-12-14T15:31:22.632734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '/kaggle/input/cache-estimator-data/dataset_lru_extra.csv'                    # Path to the dataset\n",
    "embeddings_path = '/kaggle/input/cache-estimator-data/embeddings/flow-aware-f.csv'   # Path to the embeddings\n",
    "rds, mrs = read_df(path, embeddings_path)\n",
    "# mrs = mrs.drop(columns = ['3072', '6144'])\n",
    "train_rds, train_mrs, test_rds, test_mrs = train_test_split(rds, mrs)\n",
    "\n",
    "x = []\n",
    "for i in train_rds['embeddings']:\n",
    "    x.append(i)\n",
    "train_embeddings = np.array(x)\n",
    "train_rds = train_rds.drop(columns=[\"embeddings\"])\n",
    "\n",
    "x = []\n",
    "for i in test_rds['embeddings']:\n",
    "    x.append(i)\n",
    "test_embeddings = np.array(x)\n",
    "test_rds = test_rds.drop(columns=[\"embeddings\"])\n",
    "\n",
    "train_sizes = train_rds['column']\n",
    "test_sizes = test_rds['column']\n",
    "\n",
    "train_rds = train_rds.drop(columns=[\"column\"])\n",
    "test_rds = test_rds.drop(columns=[\"column\"])\n",
    "\n",
    "embedding_scaler = StandardScaler()\n",
    "embedding_scaler = embedding_scaler.fit(train_embeddings)\n",
    "# train_embeddings = embedding_scaler.transform(train_embeddings)\n",
    "# test_embeddings  = embedding_scaler.transform(test_embeddings)\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(train_rds)\n",
    "# train_rds = scaler.transform(train_rds)\n",
    "# test_rds = scaler.transform(test_rds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2309d6e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T15:31:25.028751Z",
     "iopub.status.busy": "2023-12-14T15:31:25.028374Z",
     "iopub.status.idle": "2023-12-14T15:31:25.034633Z",
     "shell.execute_reply": "2023-12-14T15:31:25.033710Z"
    },
    "papermill": {
     "duration": 0.019776,
     "end_time": "2023-12-14T15:31:25.036774",
     "exception": false,
     "start_time": "2023-12-14T15:31:25.016998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2048.0}\n"
     ]
    }
   ],
   "source": [
    "print(set(train_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f07588e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T15:31:25.056504Z",
     "iopub.status.busy": "2023-12-14T15:31:25.056231Z",
     "iopub.status.idle": "2023-12-14T15:31:25.062008Z",
     "shell.execute_reply": "2023-12-14T15:31:25.061148Z"
    },
    "papermill": {
     "duration": 0.017787,
     "end_time": "2023-12-14T15:31:25.063984",
     "exception": false,
     "start_time": "2023-12-14T15:31:25.046197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6163, 896), (6163,), (6163, 300))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rds.shape, train_sizes.shape, train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aba595e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T15:31:25.083715Z",
     "iopub.status.busy": "2023-12-14T15:31:25.083400Z",
     "iopub.status.idle": "2023-12-14T15:31:25.089119Z",
     "shell.execute_reply": "2023-12-14T15:31:25.088317Z"
    },
    "papermill": {
     "duration": 0.017731,
     "end_time": "2023-12-14T15:31:25.090892",
     "exception": false,
     "start_time": "2023-12-14T15:31:25.073161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43141, 896), (43141,), (43141, 300))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rds.shape, test_sizes.shape, test_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573aeebd",
   "metadata": {
    "papermill": {
     "duration": 0.009143,
     "end_time": "2023-12-14T15:31:25.109240",
     "exception": false,
     "start_time": "2023-12-14T15:31:25.100097",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Error functions\n",
    "Functions to calculate the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f37cd8b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T15:31:25.128956Z",
     "iopub.status.busy": "2023-12-14T15:31:25.128711Z",
     "iopub.status.idle": "2023-12-14T15:31:25.133380Z",
     "shell.execute_reply": "2023-12-14T15:31:25.132639Z"
    },
    "papermill": {
     "duration": 0.016626,
     "end_time": "2023-12-14T15:31:25.135250",
     "exception": false,
     "start_time": "2023-12-14T15:31:25.118624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_error(x, y):\n",
    "    global test_ids\n",
    "    j='err'\n",
    "    \n",
    "    test_ids[j] = (x - y)\n",
    "    test_ids[j+'_abs'] = test_ids[j].abs()\n",
    "    print(test_ids.groupby('file_name')[j].mean().abs().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebf8ae51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T15:31:25.155256Z",
     "iopub.status.busy": "2023-12-14T15:31:25.154970Z",
     "iopub.status.idle": "2023-12-14T15:31:25.163581Z",
     "shell.execute_reply": "2023-12-14T15:31:25.162799Z"
    },
    "papermill": {
     "duration": 0.020919,
     "end_time": "2023-12-14T15:31:25.165492",
     "exception": false,
     "start_time": "2023-12-14T15:31:25.144573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_err(x, y, col_path):\n",
    "    ids = col_path\n",
    "    ids['out'] = (x - y)\n",
    "#     ids['out_abs'] = ids['1024'].abs()\n",
    "    \n",
    "    tmp = []\n",
    "    mean_df = pd.DataFrame()\n",
    "    for i in set(ids[\"column\"]):\n",
    "        means = ids[ids[\"column\"]==i].groupby('file_name')['out'].mean().to_frame()\n",
    "        means['asp'] = [x.split('-')[0] for x in means.index]\n",
    "        means['weights'] = [float(weights[x]) for x in means.index]\n",
    "        #means['weights'] = means.groupby('asp')['weights'].apply(lambda x: x / x.sum())\n",
    "        l = means.groupby('asp')['weights'].sum()\n",
    "        means['sweights'] = [l[x] for x in means['asp']]\n",
    "        means['weights'] = means['weights'] / means['sweights']\n",
    "        means['out'] = means['out'] * means['weights']\n",
    "        means = means.groupby('asp')['out'].mean().abs() # .apply(gmean) # apply(lambda x: x.max() - x.min())\n",
    "        tmp.append(gmean(means))\n",
    "#     print(i, gmean(means.abs()))\n",
    "#     plt.figure()\n",
    "#     plt.hist(means.abs(), np.linspace(0,1.0,101))\n",
    "# #         plt.yticks([*range(0,int(plt.yticks()[0][-1]))])\n",
    "#     plt.title('Histogram of predictions')\n",
    "#     plt.ylabel('# benchmarks')\n",
    "#     plt.xlabel('Error')\n",
    "#     plt.show()\n",
    "    del ids\n",
    "    return *tmp, means.mean(), mean_squared_error(x, y)\n",
    "tmp = []\n",
    "# calc_err(l[-1], test_y, cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a8a98c",
   "metadata": {
    "papermill": {
     "duration": 0.009365,
     "end_time": "2023-12-14T15:31:25.184205",
     "exception": false,
     "start_time": "2023-12-14T15:31:25.174840",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dense Neural Network\n",
    "\n",
    "Creating the DNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2781b6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T15:31:25.205136Z",
     "iopub.status.busy": "2023-12-14T15:31:25.204521Z",
     "iopub.status.idle": "2023-12-14T15:31:25.617775Z",
     "shell.execute_reply": "2023-12-14T15:31:25.616439Z"
    },
    "papermill": {
     "duration": 0.426257,
     "end_time": "2023-12-14T15:31:25.620241",
     "exception": false,
     "start_time": "2023-12-14T15:31:25.193984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X shape: (6163, 896)\n",
      "train_e shape: (6163, 300)\n",
      "train_y shape: (6163, 1)\n",
      "~~~~~~~~\n",
      "test_X shape: (43141, 896)\n",
      "test_e shape: (43141, 300)\n",
      "test_y shape: (43141, 1)\n",
      "[[ 0.03509821 -0.28592985 -0.19637353 ...  0.29874005  0.23721744\n",
      "  -0.13483197]\n",
      " [ 0.03509821 -0.28592985 -0.19637353 ...  0.29874005  0.23721744\n",
      "  -0.13483197]\n",
      " [ 0.03509821 -0.28592985 -0.19637353 ...  0.29874005  0.23721744\n",
      "  -0.13483197]\n",
      " [ 0.21592059 -0.26209304 -0.2790132  ...  0.33850083  0.39146787\n",
      "  -0.28169344]\n",
      " [ 0.21592059 -0.26209304 -0.2790132  ...  0.33850083  0.39146787\n",
      "  -0.28169344]]\n",
      "{4.0}\n",
      "{1.5, 2.0, 3.0, 6.0, 8.0, 12.0, 16.0}\n"
     ]
    }
   ],
   "source": [
    "train_y = train_mrs.to_numpy()\n",
    "test_y = test_mrs.to_numpy()\n",
    "\n",
    "# torch.save(torch.from_numpy(test_y), f'/kaggle/working/test_y_6b_cols.pt')\n",
    "\n",
    "scale = 1\n",
    "\n",
    "#x = np.array([int(i) for i in train_rds.columns])\n",
    "\n",
    "if scale:\n",
    "    embedding_scaler = StandardScaler()\n",
    "    embedding_scaler = embedding_scaler.fit(train_embeddings)\n",
    "    # train_embeddings = embedding_scaler.transform(train_embeddings)\n",
    "    # test_embeddings  = embedding_scaler.transform(test_embeddings)\n",
    "    scaler = StandardScaler()\n",
    "    scaler = scaler.fit(train_rds)\n",
    "    train_rdss = scaler.transform(train_rds)\n",
    "    test_rdss = scaler.transform(test_rds)\n",
    "    train_embeddingss = embedding_scaler.transform(train_embeddings)\n",
    "    test_embeddingss  = embedding_scaler.transform(test_embeddings)\n",
    "else:\n",
    "#     scaler2 = StandardScaler()\n",
    "#     scaler2 = scaler2.fit(train_rds.to_numpy() * x)\n",
    "    train_rdss = train_rds.to_numpy() # * x # scaler2.transform(train_rds.to_numpy() * x)\n",
    "    test_rdss = test_rds.to_numpy()   #* x # scaler2.transform(test_rds.to_numpy() * x)\n",
    "    # print(test_rdss.shape)\n",
    "    train_embeddingss = train_embeddings # embedding_scaler.transform(train_embeddings) # train_embeddings\n",
    "    test_embeddingss  = test_embeddings # embedding_scaler.transform(test_embeddings) # \n",
    "\n",
    "train_X = np.reshape(train_rdss, (train_rds.shape[0], 896))\n",
    "test_X = np.reshape(test_rdss, (test_rds.shape[0], 896))\n",
    "train_emb = np.reshape(train_embeddingss, (train_embeddings.shape[0], 300))\n",
    "test_emb = np.reshape(test_embeddingss, (test_embeddings.shape[0], 300))\n",
    "train_s = train_sizes.to_numpy()/512\n",
    "test_s = test_sizes.to_numpy()/512\n",
    "\n",
    "\n",
    "print('train_X shape:',train_X.shape)\n",
    "print('train_e shape:',train_emb.shape)\n",
    "print('train_y shape:',train_y.shape)\n",
    "print('~~~~~~~~')\n",
    "print('test_X shape:',test_X.shape)\n",
    "print('test_e shape:',test_emb.shape)\n",
    "print('test_y shape:',test_y.shape)\n",
    "print(train_emb[:5])\n",
    "print(set(train_s))\n",
    "print(set(test_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c549de18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T15:31:25.642305Z",
     "iopub.status.busy": "2023-12-14T15:31:25.641960Z",
     "iopub.status.idle": "2023-12-14T15:31:40.923243Z",
     "shell.execute_reply": "2023-12-14T15:31:40.922104Z"
    },
    "papermill": {
     "duration": 15.30407,
     "end_time": "2023-12-14T15:31:40.934566",
     "exception": false,
     "start_time": "2023-12-14T15:31:25.630496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43141, 1)\n",
      "0.43836799378744257\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 896)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1197)         0           ['input_3[0][0]',                \n",
      "                                                                  'input_2[0][0]',                \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          306688      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 257)          0           ['dense[0][0]',                  \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          66048       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 257)          0           ['dense_1[0][0]',                \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 256)          66048       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 257)          0           ['dense_2[0][0]',                \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 256)          66048       ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 257)          0           ['dense_3[0][0]',                \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1)            258         ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 505,090\n",
      "Trainable params: 505,090\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Works  \n",
    "def create_model(dnn_nodes = 1024):\n",
    "    \n",
    "    size_input = Input(shape=(1))\n",
    "    \n",
    "    embedding_inputs = Input(shape=(300))\n",
    "    \n",
    "    hist_inputs = Input(shape=(896))\n",
    "\n",
    "    inp = tf.keras.layers.Concatenate()([hist_inputs, embedding_inputs, size_input])\n",
    "\n",
    "    dense_layer1 = Dense(dnn_nodes, activation='relu')\n",
    "    dense_output = dense_layer1(inp)\n",
    "    \n",
    "    dense_output = tf.keras.layers.Concatenate()([dense_output, size_input])\n",
    "\n",
    "    dense_layer2 = Dense(dnn_nodes, activation='relu')\n",
    "    dense_output = dense_layer2(dense_output)\n",
    "    \n",
    "    dense_output = tf.keras.layers.Concatenate()([dense_output, size_input])\n",
    "\n",
    "    dense_layer3 = Dense(dnn_nodes, activation='relu')\n",
    "    dense_output = dense_layer3(dense_output)\n",
    "    \n",
    "    dense_output = tf.keras.layers.Concatenate()([dense_output, size_input])\n",
    "\n",
    "    dense_layer4 = Dense(dnn_nodes, activation='sigmoid')\n",
    "    dense_output = dense_layer4(dense_output)\n",
    "    \n",
    "    dense_output = tf.keras.layers.Concatenate()([dense_output, size_input])\n",
    "\n",
    "    output_layer = Dense(1, activation='sigmoid')\n",
    "    total_output = output_layer(dense_output)\n",
    " \n",
    "    model = Model([hist_inputs, size_input, embedding_inputs], total_output)\n",
    "    # model.summary()\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "    y_pred = model([test_X, test_s, test_emb])\n",
    "    print(y_pred.shape)\n",
    "    print(mean_squared_error(y_pred, test_y))\n",
    "    return model\n",
    "f = create_model(256)\n",
    "f.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271d99a7",
   "metadata": {
    "papermill": {
     "duration": 0.012273,
     "end_time": "2023-12-14T15:31:40.959737",
     "exception": false,
     "start_time": "2023-12-14T15:31:40.947464",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Predicting an unknown column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f80a7cf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T15:31:40.987138Z",
     "iopub.status.busy": "2023-12-14T15:31:40.986389Z",
     "iopub.status.idle": "2023-12-14T15:34:16.764625Z",
     "shell.execute_reply": "2023-12-14T15:34:16.763491Z"
    },
    "papermill": {
     "duration": 155.794358,
     "end_time": "2023-12-14T15:34:16.767099",
     "exception": false,
     "start_time": "2023-12-14T15:31:40.972741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43141, 1)\n",
      "0.3628756901618664\n",
      "97/97 [==============================] - 7s 26ms/step - loss: 0.0467 - val_loss: 0.0909\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 0.0066 - val_loss: 0.0850\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 0.0029 - val_loss: 0.0845\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 0.0022 - val_loss: 0.0827\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 0.0016 - val_loss: 0.0790\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 0.0011 - val_loss: 0.0789\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 7.6468e-04 - val_loss: 0.0814\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 8.7684e-04 - val_loss: 0.0791\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 7.3904e-04 - val_loss: 0.0803\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 5.7049e-04 - val_loss: 0.0784\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 4.6661e-04 - val_loss: 0.0789\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 4.2540e-04 - val_loss: 0.0759\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 5.2764e-04 - val_loss: 0.0777\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 5.2553e-04 - val_loss: 0.0780\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 5.8716e-04 - val_loss: 0.0772\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 4.4939e-04 - val_loss: 0.0769\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 4.6521e-04 - val_loss: 0.0732\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 4.6773e-04 - val_loss: 0.0735\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 4.4412e-04 - val_loss: 0.0721\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 5.4937e-04 - val_loss: 0.0744\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 8.0135e-04 - val_loss: 0.0726\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 5.8029e-04 - val_loss: 0.0722\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 4.3572e-04 - val_loss: 0.0688\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 5.2124e-04 - val_loss: 0.0688\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 3.4705e-04 - val_loss: 0.0672\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 3.3214e-04 - val_loss: 0.0663\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 3.3782e-04 - val_loss: 0.0685\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 3.0722e-04 - val_loss: 0.0665\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 2.8495e-04 - val_loss: 0.0659\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 7.8287e-04 - val_loss: 0.0641\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 4.3615e-04 - val_loss: 0.0649\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 3.8023e-04 - val_loss: 0.0661\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 3.9833e-04 - val_loss: 0.0653\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 3.8199e-04 - val_loss: 0.0643\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 0.0027 - val_loss: 0.0630\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 0.0041 - val_loss: 0.0587\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 0.0024 - val_loss: 0.0586\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 0.0014 - val_loss: 0.0592\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 6.3189e-04 - val_loss: 0.0572\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 4.2124e-04 - val_loss: 0.0561\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 3.7545e-04 - val_loss: 0.0570\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 2.5573e-04 - val_loss: 0.0574\n",
      "97/97 [==============================] - 4s 36ms/step - loss: 3.5113e-04 - val_loss: 0.0562\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 5.0005e-04 - val_loss: 0.0548\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 3.6503e-04 - val_loss: 0.0573\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 3.6484e-04 - val_loss: 0.0582\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 4.2248e-04 - val_loss: 0.0580\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 4.0025e-04 - val_loss: 0.0565\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 4.4504e-04 - val_loss: 0.0573\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 2.7465e-04 - val_loss: 0.0565\n"
     ]
    }
   ],
   "source": [
    "mymodel = create_model(512)\n",
    "# plot_model(mymodel, to_file='/kaggle/working/model_plot.png')\n",
    "\n",
    "l = []\n",
    "for i in range(50):\n",
    "    mymodel.fit([train_X, train_s, train_emb], train_y, epochs=1, batch_size=64, shuffle=True, validation_data=([test_X, test_s, test_emb], test_y))\n",
    "    l.append(mymodel([test_X, test_s, test_emb]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2db15d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T15:34:16.855923Z",
     "iopub.status.busy": "2023-12-14T15:34:16.855574Z",
     "iopub.status.idle": "2023-12-14T15:34:16.902935Z",
     "shell.execute_reply": "2023-12-14T15:34:16.901791Z"
    },
    "papermill": {
     "duration": 0.093643,
     "end_time": "2023-12-14T15:34:16.905065",
     "exception": false,
     "start_time": "2023-12-14T15:34:16.811422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05482730738771377\n"
     ]
    }
   ],
   "source": [
    "x = min(l, key=lambda x:mean_squared_error(x, test_y))\n",
    "print(mean_squared_error(x, test_y))\n",
    "np.save('lru_pred_known_1', x)\n",
    "np.save('lru_test_known_1', test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1747a90",
   "metadata": {
    "papermill": {
     "duration": 0.046957,
     "end_time": "2023-12-14T15:34:16.997487",
     "exception": false,
     "start_time": "2023-12-14T15:34:16.950530",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Training method of cross-validation, isolating one benchmark's at a time and moving it to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "942e1d2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T15:34:17.089732Z",
     "iopub.status.busy": "2023-12-14T15:34:17.089388Z",
     "iopub.status.idle": "2023-12-14T15:56:50.225673Z",
     "shell.execute_reply": "2023-12-14T15:56:50.224464Z"
    },
    "papermill": {
     "duration": 1353.184288,
     "end_time": "2023-12-14T15:56:50.227829",
     "exception": false,
     "start_time": "2023-12-14T15:34:17.043541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 1)\n",
      "0.09418450924333917\n",
      "97/97 [==============================] - 2s 5ms/step - loss: 0.0408 - val_loss: 0.0808\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0667\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0562\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.1188\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0784\n",
      "Best 400 : 0.056239205524090945\n",
      "(416, 1)\n",
      "0.04042166851343248\n",
      "96/96 [==============================] - 2s 5ms/step - loss: 0.0341 - val_loss: 0.0695\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0521\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0504\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0639\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0479\n",
      "Best 401 : 0.04602825283923197\n",
      "(720, 1)\n",
      "0.3534184316968012\n",
      "95/95 [==============================] - 2s 5ms/step - loss: 0.0319 - val_loss: 0.1196\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0776\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.1001\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0865\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0839\n",
      "Best 403 : 0.07269258318414902\n",
      "(808, 1)\n",
      "0.7913332303091661\n",
      "95/95 [==============================] - 2s 5ms/step - loss: 0.0432 - val_loss: 0.0215\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0176\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0031 - val_loss: 0.0239\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0508\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0157\n",
      "Best 410 : 0.0029275426421590694\n",
      "(8, 1)\n",
      "0.012206381855088573\n",
      "97/97 [==============================] - 2s 6ms/step - loss: 0.0382 - val_loss: 0.3499\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.3356\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.4238\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.3352\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.3802\n",
      "Best 416 : 0.1205834430845593\n",
      "(6776, 1)\n",
      "0.12891309692761338\n",
      "84/84 [==============================] - 3s 8ms/step - loss: 0.0406 - val_loss: 0.2644\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0060 - val_loss: 0.3058\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.2852\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0024 - val_loss: 0.2930\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.3130\n",
      "Best 429 : 0.25358535661359793\n",
      "(1240, 1)\n",
      "0.6413890241805594\n",
      "94/94 [==============================] - 2s 6ms/step - loss: 0.0382 - val_loss: 0.0149\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.0057 - val_loss: 0.0090\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0094\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0112\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0142\n",
      "Best 433 : 0.009049030746854822\n",
      "(88, 1)\n",
      "0.08228909525872642\n",
      "97/97 [==============================] - 2s 5ms/step - loss: 0.0306 - val_loss: 0.0451\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0719\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0615\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0597\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0718\n",
      "Best 434 : 0.03817418769457268\n",
      "(72, 1)\n",
      "0.09067339488221313\n",
      "97/97 [==============================] - 2s 5ms/step - loss: 0.0353 - val_loss: 0.1992\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.2094\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.1001\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.1931\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.1843\n",
      "Best 435 : 0.100085389879108\n",
      "(112, 1)\n",
      "0.05264547160959483\n",
      "97/97 [==============================] - 2s 5ms/step - loss: 0.0391 - val_loss: 0.0211\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0249\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0591\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0168\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0123\n",
      "Best 436 : 0.004218816072048869\n",
      "(1000, 1)\n",
      "0.04287871324663983\n",
      "95/95 [==============================] - 2s 6ms/step - loss: 0.0370 - val_loss: 0.0157\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0088\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0115\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0141\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0102\n",
      "Best 437 : 0.008834327196944944\n",
      "(56, 1)\n",
      "0.11545010207192206\n",
      "97/97 [==============================] - 2s 5ms/step - loss: 0.0357 - val_loss: 0.0960\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0509\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.1101\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.1641\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0529\n",
      "Best 444 : 0.05087029337186751\n",
      "(88, 1)\n",
      "0.11940350592772891\n",
      "97/97 [==============================] - 2s 5ms/step - loss: 0.0412 - val_loss: 0.1211\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0956\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0915\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0961\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.1173\n",
      "Best 445 : 0.05252235672872341\n",
      "(32, 1)\n",
      "0.22122455791876855\n",
      "97/97 [==============================] - 3s 5ms/step - loss: 0.0360 - val_loss: 0.1971\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.2337\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.2621\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.2327\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.2021\n",
      "Best 447 : 0.18228904892482817\n",
      "(1464, 1)\n",
      "0.21019740537784556\n",
      "94/94 [==============================] - 2s 6ms/step - loss: 0.0468 - val_loss: 0.3005\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.0056 - val_loss: 0.2292\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.2653\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.2693\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.2869\n",
      "Best 450 : 0.22917412802333753\n",
      "(32, 1)\n",
      "0.06993015948530909\n",
      "97/97 [==============================] - 2s 5ms/step - loss: 0.0410 - val_loss: 0.0656\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.2548\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0206\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.1160\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.1226\n",
      "Best 453 : 0.02058754245065987\n",
      "(112, 1)\n",
      "0.055375496116558155\n",
      "97/97 [==============================] - 2s 5ms/step - loss: 0.0379 - val_loss: 0.1313\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.1984\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.2671\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.2472\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.2540\n",
      "Best 454 : 0.1312892421862557\n",
      "(168, 1)\n",
      "0.19669072076759916\n",
      "96/96 [==============================] - 2s 5ms/step - loss: 0.0364 - val_loss: 0.2346\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.2503\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.2203\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.1857\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.1680\n",
      "Best 456 : 0.16428414188248716\n",
      "(32, 1)\n",
      "0.21954971019732586\n",
      "97/97 [==============================] - 3s 6ms/step - loss: 0.0364 - val_loss: 6.6412e-04\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0026\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0213\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 0.0017 - val_loss: 0.0197\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.1060\n",
      "Best 458 : 0.0006641158272334809\n",
      "(1536, 1)\n",
      "0.20166918971965728\n",
      "94/94 [==============================] - 2s 6ms/step - loss: 0.0394 - val_loss: 0.0761\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.0524\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0670\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0412\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0371\n",
      "Best 459 : 0.015602117584781272\n",
      "(1104, 1)\n",
      "0.48947252134030556\n",
      "95/95 [==============================] - 2s 6ms/step - loss: 0.0366 - val_loss: 0.0218\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0343\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0180\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0087\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Best 462 : 0.0022404856694408543\n",
      "(128, 1)\n",
      "0.3980420315961587\n",
      "97/97 [==============================] - 2s 5ms/step - loss: 0.0382 - val_loss: 0.1698\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.1387\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.2134\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.1819\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.1165\n",
      "Best 464 : 0.11654193475488825\n",
      "(624, 1)\n",
      "0.1020473688312358\n",
      "96/96 [==============================] - 2s 5ms/step - loss: 0.0321 - val_loss: 0.2555\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.4167\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.3823\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.2523\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.3271\n",
      "Best 470 : 0.24592751344540317\n",
      "(448, 1)\n",
      "0.13665641479411156\n",
      "96/96 [==============================] - 2s 5ms/step - loss: 0.0367 - val_loss: 0.1732\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.2453\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.2196\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.2492\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.2292\n",
      "Best 471 : 0.17322920666747507\n",
      "(1136, 1)\n",
      "0.10149410019554016\n",
      "95/95 [==============================] - 3s 6ms/step - loss: 0.0313 - val_loss: 0.1443\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0055 - val_loss: 0.1408\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.1453\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.1626\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.1541\n",
      "Best 473 : 0.14078835477504661\n",
      "(672, 1)\n",
      "0.23097380994451105\n",
      "95/95 [==============================] - 2s 6ms/step - loss: 0.0369 - val_loss: 0.0887\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0752\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.1054\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0753\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0680\n",
      "Best 481 : 0.02420986596660469\n",
      "(1688, 1)\n",
      "0.3771474186296434\n",
      "93/93 [==============================] - 2s 6ms/step - loss: 0.0397 - val_loss: 0.4405\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.3957\n",
      "93/93 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.4369\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.4244\n",
      "93/93 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.4412\n",
      "Best 482 : 0.39573501921310916\n",
      "(696, 1)\n",
      "0.10799531883666022\n",
      "95/95 [==============================] - 2s 6ms/step - loss: 0.0407 - val_loss: 0.2584\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.1718\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.3032\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.2522\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.3317\n",
      "Best 483 : 0.17183163008257687\n",
      "(32, 1)\n",
      "0.11760641781722687\n",
      "97/97 [==============================] - 2s 5ms/step - loss: 0.0291 - val_loss: 0.1245\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.1109\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.1182\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.2780\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.1603\n",
      "Best 600 : 0.10573291231320683\n",
      "(2104, 1)\n",
      "0.16595255665209477\n",
      "93/93 [==============================] - 2s 6ms/step - loss: 0.0402 - val_loss: 0.5510\n",
      "93/93 [==============================] - 0s 5ms/step - loss: 0.0065 - val_loss: 0.1483\n",
      "93/93 [==============================] - 0s 5ms/step - loss: 0.0031 - val_loss: 0.1210\n",
      "93/93 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.4459\n",
      "93/93 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.2222\n",
      "Best 602 : 0.10915229698893217\n",
      "(1672, 1)\n",
      "0.7056339038589318\n",
      "94/94 [==============================] - 2s 6ms/step - loss: 0.0402 - val_loss: 0.2527\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.0055 - val_loss: 0.2906\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.0032 - val_loss: 0.2384\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.3320\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.3685\n",
      "Best 603 : 0.0008922237267295616\n",
      "(12512, 1)\n",
      "0.12871534289920536\n",
      "72/72 [==============================] - 3s 13ms/step - loss: 0.0502 - val_loss: 0.1856\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0050 - val_loss: 0.2006\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0030 - val_loss: 0.2129\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0024 - val_loss: 0.2058\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0024 - val_loss: 0.2229\n",
      "Best 605 : 0.18563652819525317\n",
      "(528, 1)\n",
      "0.025163354944966597\n",
      "96/96 [==============================] - 3s 6ms/step - loss: 0.0304 - val_loss: 0.1525\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0879\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0856\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.1026\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0946\n",
      "Best 607 : 0.06545976728814708\n",
      "(3584, 1)\n",
      "0.4884954804164205\n",
      "90/90 [==============================] - 2s 7ms/step - loss: 0.0410 - val_loss: 0.0597\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.0060 - val_loss: 0.0512\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0432\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 0.0200\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0490\n",
      "Best 619 : 0.019971189498616326\n",
      "(568, 1)\n",
      "0.007455264964257621\n",
      "96/96 [==============================] - 2s 5ms/step - loss: 0.0466 - val_loss: 0.0038\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0139\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0148\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0061\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0116\n",
      "Best 620 : 0.003758555575776016\n",
      "(600, 1)\n",
      "0.4895005938708678\n",
      "96/96 [==============================] - 2s 5ms/step - loss: 0.0361 - val_loss: 0.0517\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.0058 - val_loss: 0.0368\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0332\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0318\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0372\n",
      "Best 621 : 0.03006187946636517\n",
      "(1688, 1)\n",
      "0.16609780651617503\n",
      "93/93 [==============================] - 2s 5ms/step - loss: 0.0346 - val_loss: 0.2401\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.2378\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.2375\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.2595\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.2607\n",
      "Best 623 : 0.22779443635465133\n",
      "(96, 1)\n",
      "0.03223758450253539\n",
      "97/97 [==============================] - 2s 6ms/step - loss: 0.0313 - val_loss: 0.1865\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.2168\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.1083\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.1946\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.1318\n",
      "Best 625 : 0.06851995407803026\n",
      "(384, 1)\n",
      "0.1267819656118506\n",
      "96/96 [==============================] - 2s 6ms/step - loss: 0.0349 - val_loss: 0.1250\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.1174\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.1627\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.1704\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.1683\n",
      "Best 627 : 0.11737453272955749\n",
      "(8, 1)\n",
      "0.2890188359218617\n",
      "97/97 [==============================] - 2s 5ms/step - loss: 0.0383 - val_loss: 0.2812\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.2744\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.3756\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0526\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.1773\n",
      "Best 631 : 0.05262901310586659\n",
      "(24, 1)\n",
      "0.2150191603615164\n",
      "97/97 [==============================] - 2s 5ms/step - loss: 0.0373 - val_loss: 0.0798\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0500\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0304\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0469\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0360\n",
      "Best 638 : 0.02766202220587774\n",
      "(64, 1)\n",
      "0.23902273907541682\n",
      "97/97 [==============================] - 2s 5ms/step - loss: 0.0432 - val_loss: 0.2667\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.2390\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.2740\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.3314\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.3234\n",
      "Best 641 : 0.2390032028414747\n",
      "(72, 1)\n",
      "0.1118228409909705\n",
      "97/97 [==============================] - 2s 5ms/step - loss: 0.0323 - val_loss: 0.2292\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.4720\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 0.0032 - val_loss: 0.4854\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.4516\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.3168\n",
      "Best 644 : 0.22917973785056908\n",
      "(80, 1)\n",
      "0.32537546151104385\n",
      "97/97 [==============================] - 2s 5ms/step - loss: 0.0349 - val_loss: 0.2370\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.3973\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0764\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0448\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0685\n",
      "Best 648 : 0.0011586317713490057\n",
      "(1160, 1)\n",
      "0.2995016549914157\n",
      "95/95 [==============================] - 2s 6ms/step - loss: 0.0446 - val_loss: 0.1088\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.1768\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.1694\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0553\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0819\n",
      "Best 649 : 0.007625748279599027\n",
      "(2728, 1)\n",
      "0.22296305737644118\n",
      "91/91 [==============================] - 2s 6ms/step - loss: 0.0350 - val_loss: 0.1986\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.0056 - val_loss: 0.2061\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.2026\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.2209\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.2036\n",
      "Best 654 : 0.1633587929472085\n",
      "(120, 1)\n",
      "0.07942531999176887\n",
      "97/97 [==============================] - 3s 11ms/step - loss: 0.0354 - val_loss: 0.1421\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.2390\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.2316\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.2031\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.2584\n",
      "Best 657 : 0.14209469668316477\n"
     ]
    }
   ],
   "source": [
    "test_ids = pd.DataFrame()\n",
    "test_outputs = pd.DataFrame()\n",
    "test_preds = pd.DataFrame()\n",
    "for bench in rds['source_file'].unique():\n",
    "    train_rds, train_mrs, test_rds, test_mrs  = train_test_split_sec(rds, mrs, [bench])\n",
    "    train_y = train_mrs.to_numpy()\n",
    "    test_y = test_mrs.to_numpy()\n",
    "\n",
    "    x = []\n",
    "    for i in train_rds['embeddings']:\n",
    "        x.append(i)\n",
    "    train_embeddings = np.array(x)\n",
    "    train_rds = train_rds.drop(columns=[\"embeddings\"])\n",
    "\n",
    "    x = []\n",
    "    for i in test_rds['embeddings']:\n",
    "        x.append(i)\n",
    "    test_embeddings = np.array(x)\n",
    "    test_rds = test_rds.drop(columns=[\"embeddings\"])\n",
    "\n",
    "    train_sizes = train_rds['column']\n",
    "    test_sizes = test_rds['column']\n",
    "\n",
    "    train_rds = train_rds.drop(columns=[\"column\"])\n",
    "    test_rds = test_rds.drop(columns=[\"column\"])\n",
    "\n",
    "    embedding_scaler = StandardScaler()\n",
    "    embedding_scaler = embedding_scaler.fit(train_embeddings)\n",
    "    # train_embeddings = embedding_scaler.transform(train_embeddings)\n",
    "    # test_embeddings  = embedding_scaler.transform(test_embeddings)\n",
    "    scaler = StandardScaler()\n",
    "    scaler = scaler.fit(train_rds)\n",
    "\n",
    "    #x = np.array([int(i) for i in train_rds.columns])\n",
    "    scale = 1\n",
    "\n",
    "    if scale:\n",
    "        train_rdss = scaler.transform(train_rds)\n",
    "        test_rdss = scaler.transform(test_rds)\n",
    "        train_embeddingss = embedding_scaler.transform(train_embeddings)\n",
    "        test_embeddingss  = embedding_scaler.transform(test_embeddings)\n",
    "    else:\n",
    "    #     scaler2 = StandardScaler()\n",
    "    #     scaler2 = scaler2.fit(train_rds.to_numpy() * x)\n",
    "        train_rdss = train_rds.to_numpy() # * x # scaler2.transform(train_rds.to_numpy() * x)\n",
    "        test_rdss = test_rds.to_numpy()   #* x # scaler2.transform(test_rds.to_numpy() * x)\n",
    "        # print(test_rdss.shape)\n",
    "        train_embeddingss = train_embeddings # embedding_scaler.transform(train_embeddings) # train_embeddings\n",
    "        test_embeddingss  = test_embeddings # embedding_scaler.transform(test_embeddings) # \n",
    "\n",
    "\n",
    "    train_X = np.reshape(train_rdss, (train_rds.shape[0], 896))\n",
    "    test_X = np.reshape(test_rdss, (test_rds.shape[0], 896))\n",
    "    train_emb = np.reshape(train_embeddingss, (train_embeddings.shape[0], 300))\n",
    "    test_emb = np.reshape(test_embeddingss, (test_embeddings.shape[0], 300))\n",
    "    train_s = train_sizes.to_numpy()/512\n",
    "    test_s = test_sizes.to_numpy()/512\n",
    "    mymodel = create_model(512)\n",
    "    l = []\n",
    "    for i in range(50):\n",
    "        mymodel.fit([train_X, train_s, train_emb], train_y, epochs=1, batch_size=64, shuffle=True, validation_data=([test_X, test_s, test_emb], test_y), verbose = i < 5)\n",
    "        l.append(mymodel([test_X, test_s, test_emb]))\n",
    "    x = min(l, key=lambda x:mean_squared_error(x, test_y))\n",
    "    print('Best', bench, ':', mean_squared_error(x, test_y))\n",
    "    d = pd.DataFrame(x)\n",
    "    test_preds = pd.concat([test_preds, d], ignore_index=True)\n",
    "np.save(f'/kaggle/working/dnn_names_3', test_ids.to_numpy())\n",
    "np.save(f'/kaggle/working/dnn_test_y_3', test_outputs.to_numpy())\n",
    "np.save(f'/kaggle/working/dnn_preds_3', test_preds.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "781eca4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T15:56:50.622578Z",
     "iopub.status.busy": "2023-12-14T15:56:50.622181Z",
     "iopub.status.idle": "2023-12-14T15:56:50.627568Z",
     "shell.execute_reply": "2023-12-14T15:56:50.626640Z"
    },
    "papermill": {
     "duration": 0.20471,
     "end_time": "2023-12-14T15:56:50.629444",
     "exception": false,
     "start_time": "2023-12-14T15:56:50.424734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49304, 4) (49304, 1) (49304, 1)\n"
     ]
    }
   ],
   "source": [
    "print(test_ids.shape, test_outputs.shape, test_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "522c920d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T15:56:51.026098Z",
     "iopub.status.busy": "2023-12-14T15:56:51.025705Z",
     "iopub.status.idle": "2023-12-14T15:56:51.052103Z",
     "shell.execute_reply": "2023-12-14T15:56:51.051092Z"
    },
    "papermill": {
     "duration": 0.226927,
     "end_time": "2023-12-14T15:56:51.054293",
     "exception": false,
     "start_time": "2023-12-14T15:56:50.827366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(f'/kaggle/working/dnn_names_1', test_ids.to_numpy())\n",
    "np.save(f'/kaggle/working/dnn_test_y_1', test_outputs.to_numpy())\n",
    "np.save(f'/kaggle/working/dnn_preds_1', test_preds.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea367adb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T15:56:51.446731Z",
     "iopub.status.busy": "2023-12-14T15:56:51.446368Z",
     "iopub.status.idle": "2023-12-14T15:56:51.463917Z",
     "shell.execute_reply": "2023-12-14T15:56:51.462976Z"
    },
    "papermill": {
     "duration": 0.21465,
     "end_time": "2023-12-14T15:56:51.465808",
     "exception": false,
     "start_time": "2023-12-14T15:56:51.251158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = min(l, key=lambda x:mean_squared_error(x, test_y))\n",
    "d = pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ce32b10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T15:56:51.861434Z",
     "iopub.status.busy": "2023-12-14T15:56:51.861029Z",
     "iopub.status.idle": "2023-12-14T15:56:53.153647Z",
     "shell.execute_reply": "2023-12-14T15:56:53.152361Z"
    },
    "papermill": {
     "duration": 1.495706,
     "end_time": "2023-12-14T15:56:53.155693",
     "exception": true,
     "start_time": "2023-12-14T15:56:51.659987",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/working/id_col_lru_other_6b.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cp \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/id_col_lru_other_6b.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m tmp \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m l:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/id_col_lru_other_6b.csv'"
     ]
    }
   ],
   "source": [
    "cp = pd.read_csv('/kaggle/working/id_col_lru_other_6b.csv')\n",
    "tmp = []\n",
    "for x in l:\n",
    "    tmp.append(calc_err(x, test_y, cp))\n",
    "print(test_y.shape)\n",
    "x = min(l, key=lambda x:np.mean(calc_err(x, test_y, cp)[:-2]))\n",
    "torch.save(x, f'/kaggle/working/lru_changing_6b_cols.pt')\n",
    "print(calc_err(x, test_y, cp))\n",
    "print(min(tmp, key=lambda x : np.mean(x[:-2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0cedaf",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-28T08:49:55.492866Z",
     "iopub.status.idle": "2023-11-28T08:49:55.493236Z",
     "shell.execute_reply": "2023-11-28T08:49:55.493079Z",
     "shell.execute_reply.started": "2023-11-28T08:49:55.493062Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_err(x, y, col_path):\n",
    "    ids = col_path\n",
    "    ids['out'] = (x - y)\n",
    "#     ids['out_abs'] = ids['1024'].abs()\n",
    "    \n",
    "    tmp = []\n",
    "    mean_df = pd.DataFrame()\n",
    "    for i in set(ids[\"column\"]):\n",
    "        means = ids[ids[\"column\"]==i].groupby('file_name')['out'].mean().to_frame()\n",
    "        means['asp'] = [x.split('-')[0] for x in means.index]\n",
    "        means['weights'] = [float(weights[x]) for x in means.index]\n",
    "        #means['weights'] = means.groupby('asp')['weights'].apply(lambda x: x / x.sum())\n",
    "        l = means.groupby('asp')['weights'].sum()\n",
    "        means['sweights'] = [l[x] for x in means['asp']]\n",
    "        means['weights'] = means['weights'] / means['sweights']\n",
    "        means['out'] = means['out'] * means['weights']\n",
    "        means = means.groupby('asp')['out'].sum().abs() # .apply(gmean) # apply(lambda x: x.max() - x.min())\n",
    "        tmp.append(gmean(means))\n",
    "#     print(i, gmean(means.abs()))\n",
    "#     plt.figure()\n",
    "#     plt.hist(means.abs(), np.linspace(0,1.0,101))\n",
    "# #         plt.yticks([*range(0,int(plt.yticks()[0][-1]))])\n",
    "#     plt.title('Histogram of predictions')\n",
    "#     plt.ylabel('# benchmarks')\n",
    "#     plt.xlabel('Error')\n",
    "#     plt.show()\n",
    "    del ids\n",
    "    return *tmp, means.mean(), mean_squared_error(x, y)\n",
    "tmp = []\n",
    "calc_err(l[-1], test_y, cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2d57b7",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-28T08:49:55.494797Z",
     "iopub.status.idle": "2023-11-28T08:49:55.495128Z",
     "shell.execute_reply": "2023-11-28T08:49:55.494978Z",
     "shell.execute_reply.started": "2023-11-28T08:49:55.494963Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in l:\n",
    "    calc_error(i, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207dbd63",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-28T08:49:55.496142Z",
     "iopub.status.idle": "2023-11-28T08:49:55.496502Z",
     "shell.execute_reply": "2023-11-28T08:49:55.496330Z",
     "shell.execute_reply.started": "2023-11-28T08:49:55.496313Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = min(l, key=lambda x:mean_squared_error(x, test_y))\n",
    "torch.save(x, f'/kaggle/working/lru_other')\n",
    "x = torch.from_numpy(test_y)\n",
    "torch.save(x, f'/kaggle/working/test_y_other.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb1df94",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-28T08:49:55.497816Z",
     "iopub.status.idle": "2023-11-28T08:49:55.498267Z",
     "shell.execute_reply": "2023-11-28T08:49:55.498059Z",
     "shell.execute_reply.started": "2023-11-28T08:49:55.498034Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = min(l, key=lambda x:mean_absolute_error(x, test_y))\n",
    "print(mean_absolute_error(x, test_y))\n",
    "torch.save(x, f'/kaggle/working/lru_other.pt')\n",
    "#x = torch.from_numpy(test_y)\n",
    "#torch.save(x, f'/kaggle/working/test_y_other.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b997d9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-28T08:49:55.499866Z",
     "iopub.status.idle": "2023-11-28T08:49:55.500355Z",
     "shell.execute_reply": "2023-11-28T08:49:55.500137Z",
     "shell.execute_reply.started": "2023-11-28T08:49:55.500113Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_err(x, y, col_path):\n",
    "    ids = col_path\n",
    "    ids['1024'] = (x - y)\n",
    "    ids['1024_abs'] = ids['1024'].abs()\n",
    "    tmp = []\n",
    "    mean_df = pd.DataFrame()\n",
    "    i = '1024'\n",
    "    means = ids.groupby('file_name')[i].mean().to_frame()\n",
    "    means['asp'] = [x.split('-')[0] for x in means.index]\n",
    "    means['weights'] = [float(weights[x]) for x in means.index]\n",
    "    #means['weights'] = means.groupby('asp')['weights'].apply(lambda x: x / x.sum())\n",
    "    l = means.groupby('asp')['weights'].sum()\n",
    "    means['sweights'] = [l[x] for x in means['asp']]\n",
    "    means['weights'] = means['weights'] / means['sweights']\n",
    "    means[i] = means[i] * means['weights']\n",
    "    means = means.groupby('asp')[i].mean().abs() # .apply(gmean) # apply(lambda x: x.max() - x.min())\n",
    "#     print(gmean(means))\n",
    "#     print(means.mean())\n",
    "#     print(i, gmean(means.abs()))\n",
    "#     plt.figure()\n",
    "#     plt.hist(means.abs(), np.linspace(0,1.0,101))\n",
    "# #         plt.yticks([*range(0,int(plt.yticks()[0][-1]))])\n",
    "#     plt.title('Histogram of predictions')\n",
    "#     plt.ylabel('# benchmarks')\n",
    "#     plt.xlabel('Error')\n",
    "#     plt.show()\n",
    "    return gmean(means), means.mean()\n",
    "cp = pd.read_csv('/kaggle/working/id_col_lru_other.csv')\n",
    "tmp = []\n",
    "for x in l:\n",
    "    tmp.append(calc_err(x, test_y, cp))\n",
    "\n",
    "x = min(l, key=lambda x:calc_err(x, test_y, cp)[0])\n",
    "print(calc_err(x, test_y, cp))\n",
    "calc_err(x, test_y, cp)\n",
    "print(min(tmp, key=lambda x : x[0]))\n",
    "print(min(tmp, key=lambda x : x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8932e08a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3621875,
     "sourceId": 6614024,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30559,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1567.148218,
   "end_time": "2023-12-14T15:56:57.340987",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-14T15:30:50.192769",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
