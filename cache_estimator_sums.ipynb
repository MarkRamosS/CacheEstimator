{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3008758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import csv\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.metrics import MeanSquaredError\n",
    "from keras.losses import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f76ca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "path = '../ce_data/output_512/dataset_ship.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2024b8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df(path):\n",
    "    # Read csv\n",
    "    df = pd.read_csv(path)\n",
    "    # Calculate miss ratios in seperate dataframe\n",
    "    miss_ratios = pd.DataFrame()\n",
    "    for i in [\"1024\",\"2048\",\"4096\",\"8192\"]:\n",
    "        miss_ratios[i] = df['misses_'+i] / df['accesses_'+i]\n",
    "        df = df.drop(columns=['misses_'+i, 'accesses_'+i])\n",
    "        if 'l1d_accesses_'+i in df.columns:\n",
    "            df = df.drop(columns=['l1d_accesses_'+i])\n",
    "    # Append filename column\n",
    "    filenames = []\n",
    "    for i in df[\"id\"]:\n",
    "        nmb = i.split('_')[-1]\n",
    "        filenames.append(i[:-len(nmb)-1])\n",
    "    df[\"file_name\"] = filenames\n",
    "    filenames = list(set(filenames))\n",
    "    return df, miss_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ab17d3",
   "metadata": {},
   "source": [
    "There's a chance that reuse distance histograms within files are similar to each other. This may be due to them being sampled from the same files and therefore generated from the same code, so the histograms will be similar. To avoid this interfering with our process, we'll be moving all the lines that are derived from randomly picked files until they add up to 20% of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23e2c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, miss_ratios, split=0.3):\n",
    "    filenames = list(set(df[\"file_name\"]))\n",
    "    collected_rows = 0\n",
    "    files = []\n",
    "    while len(df) * split > collected_rows:\n",
    "        rf = filenames[random.randint(0,188)]\n",
    "        if rf in files: # No duplicates\n",
    "            continue\n",
    "        files.append(rf)\n",
    "        collected_rows += len(df[df[\"file_name\"] == rf])\n",
    "\n",
    "    train_rds = df[~df[\"file_name\"].isin(files)]\n",
    "    train_mrs = miss_ratios[~df[\"file_name\"].isin(files)]\n",
    "    test_rds = df[df[\"file_name\"].isin(files)]\n",
    "    test_mrs = miss_ratios[df[\"file_name\"].isin(files)]\n",
    "    print(f\"The test set consists of {len(files)} files (out of 189) with a total of {collected_rows} rows (out of {len(df)})\")\n",
    "    train_rds = train_rds.drop(columns=[\"id\", \"file_name\"])\n",
    "    test_rds = test_rds.drop(columns=[\"id\", \"file_name\"])\n",
    "    return train_rds, train_mrs, test_rds, test_mrs\n",
    "#train_rds, train_mrs, test_rds, test_mrs = train_test_split(rds, mrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f88e8f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_model(layers=[896,896,1]):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(896, input_dim=896, activation='sigmoid'))\n",
    "    \n",
    "    # Add layers\n",
    "    for i in range(1, len(layers)):\n",
    "        model.add(Dense(layers[i], activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss=\"mse\" , optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7608982",
   "metadata": {},
   "source": [
    "# Ship replacement Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd7f3fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test set consists of 54 files (out of 189) with a total of 1547 rows (out of 6182)\n"
     ]
    }
   ],
   "source": [
    "rds, mrs = read_df('../ce_data/output_512/dataset_ship.csv')\n",
    "train_rds, train_mrs, test_rds, test_mrs = train_test_split(rds, mrs, split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fcd7fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 896)               803712    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 896)               803712    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 3588      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,611,012\n",
      "Trainable params: 1,611,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.0550\n",
      "Epoch 2/2\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0380\n",
      "Mean squared error for cache size 1024\t: 0.08750855828280242\n",
      "Mean squared error for cache size 2048\t: 0.07424994561614187\n",
      "Mean squared error for cache size 4096\t: 0.07043049673216144\n",
      "Mean squared error for cache size 8192\t: 0.08765517250861413\n",
      "Epoch 1/2\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0282\n",
      "Epoch 2/2\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0209\n",
      "Mean squared error for cache size 1024\t: 0.05764714121041728\n",
      "Mean squared error for cache size 2048\t: 0.08329402458437932\n",
      "Mean squared error for cache size 4096\t: 0.10171334095002307\n",
      "Mean squared error for cache size 8192\t: 0.09451644511716704\n",
      "Epoch 1/2\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0189\n",
      "Epoch 2/2\n",
      "145/145 [==============================] - 1s 9ms/step - loss: 0.0162\n",
      "Mean squared error for cache size 1024\t: 0.06344716233124485\n",
      "Mean squared error for cache size 2048\t: 0.09059309859175547\n",
      "Mean squared error for cache size 4096\t: 0.09317170083875034\n",
      "Mean squared error for cache size 8192\t: 0.09607841626388079\n",
      "Epoch 1/2\n",
      "145/145 [==============================] - 1s 9ms/step - loss: 0.0148\n",
      "Epoch 2/2\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0142\n",
      "Mean squared error for cache size 1024\t: 0.06347904158045226\n",
      "Mean squared error for cache size 2048\t: 0.09087668190150744\n",
      "Mean squared error for cache size 4096\t: 0.09741063220010954\n",
      "Mean squared error for cache size 8192\t: 0.09506645375652586\n",
      "Epoch 1/2\n",
      "145/145 [==============================] - 1s 9ms/step - loss: 0.0127\n",
      "Epoch 2/2\n",
      "145/145 [==============================] - 1s 9ms/step - loss: 0.0127\n",
      "Mean squared error for cache size 1024\t: 0.06667490096465135\n",
      "Mean squared error for cache size 2048\t: 0.08940194445624612\n",
      "Mean squared error for cache size 4096\t: 0.08922550378445704\n",
      "Mean squared error for cache size 8192\t: 0.09435531738147089\n",
      "Epoch 1/2\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0118\n",
      "Epoch 2/2\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0117\n",
      "Mean squared error for cache size 1024\t: 0.06774979090659956\n",
      "Mean squared error for cache size 2048\t: 0.0918800684809547\n",
      "Mean squared error for cache size 4096\t: 0.09466157791789774\n",
      "Mean squared error for cache size 8192\t: 0.09941751134048982\n",
      "Epoch 1/2\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0117\n",
      "Epoch 2/2\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0105\n",
      "Mean squared error for cache size 1024\t: 0.06113252089219938\n",
      "Mean squared error for cache size 2048\t: 0.0786112731406005\n",
      "Mean squared error for cache size 4096\t: 0.08708759543890147\n",
      "Mean squared error for cache size 8192\t: 0.09312328181802249\n",
      "Epoch 1/2\n",
      "145/145 [==============================] - 1s 9ms/step - loss: 0.0101\n",
      "Epoch 2/2\n",
      "145/145 [==============================] - 1s 9ms/step - loss: 0.0097\n",
      "Mean squared error for cache size 1024\t: 0.06325018270991943\n",
      "Mean squared error for cache size 2048\t: 0.08666975095027989\n",
      "Mean squared error for cache size 4096\t: 0.09098061518923554\n",
      "Mean squared error for cache size 8192\t: 0.09135491628182758\n",
      "Epoch 1/2\n",
      "145/145 [==============================] - 1s 9ms/step - loss: 0.0101\n",
      "Epoch 2/2\n",
      "145/145 [==============================] - 1s 9ms/step - loss: 0.0098\n",
      "Mean squared error for cache size 1024\t: 0.058876915062408226\n",
      "Mean squared error for cache size 2048\t: 0.08335399362605603\n",
      "Mean squared error for cache size 4096\t: 0.08847600841028251\n",
      "Mean squared error for cache size 8192\t: 0.08891526471767977\n",
      "Epoch 1/2\n",
      "145/145 [==============================] - 2s 10ms/step - loss: 0.0102\n",
      "Epoch 2/2\n",
      "145/145 [==============================] - 2s 11ms/step - loss: 0.0092\n",
      "Mean squared error for cache size 1024\t: 0.05940974055290502\n",
      "Mean squared error for cache size 2048\t: 0.08357127183754348\n",
      "Mean squared error for cache size 4096\t: 0.09609590048618225\n",
      "Mean squared error for cache size 8192\t: 0.09522645629599918\n"
     ]
    }
   ],
   "source": [
    "j = ['1024', '2048', '4096', '8192']\n",
    "m = dnn_model([896,896,len(j)])\n",
    "m.summary()\n",
    "for i in range(10):\n",
    "    m.fit(train_rds.to_numpy(), train_mrs[j].to_numpy(), epochs=2)\n",
    "#    for i,k in enumerate(j):\n",
    "#        print(mean_squared_error(m(train_rds.to_numpy())[:,i], train_mrs[k].to_numpy()))\n",
    "    for i,k in enumerate(j):\n",
    "        print(f'Mean squared error for cache size {k}\\t: {mean_squared_error(m(test_rds.to_numpy())[:,i], test_mrs[k].to_numpy())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6c792d",
   "metadata": {},
   "source": [
    "# LRU replacement Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6694d9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test set consists of 36 files (out of 189) with a total of 1708 rows (out of 6183)\n"
     ]
    }
   ],
   "source": [
    "rds, mrs = read_df('../ce_data/output_512/dataset_lru.csv')\n",
    "# print(rds, mrs)\n",
    "train_rds, train_mrs, test_rds, test_mrs = train_test_split(rds, mrs, split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2110edab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 896)               803712    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 896)               803712    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 3588      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,611,012\n",
      "Trainable params: 1,611,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "140/140 [==============================] - 2s 10ms/step - loss: 0.0692\n",
      "Epoch 2/2\n",
      "140/140 [==============================] - 1s 10ms/step - loss: 0.0531\n",
      "Mean squared error for cache size 1024\t: 0.012875371123205047\n",
      "Mean squared error for cache size 2048\t: 0.03507795809186156\n",
      "Mean squared error for cache size 4096\t: 0.07685864715052503\n",
      "Mean squared error for cache size 8192\t: 0.10061846873134875\n",
      "Epoch 1/2\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.0279\n",
      "Epoch 2/2\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.0235\n",
      "Mean squared error for cache size 1024\t: 0.019282952563548856\n",
      "Mean squared error for cache size 2048\t: 0.05734439860982921\n",
      "Mean squared error for cache size 4096\t: 0.07919937879926432\n",
      "Mean squared error for cache size 8192\t: 0.0889728637889905\n",
      "Epoch 1/2\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0192\n",
      "Epoch 2/2\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0181\n",
      "Mean squared error for cache size 1024\t: 0.04317680028355681\n",
      "Mean squared error for cache size 2048\t: 0.09992872106174458\n",
      "Mean squared error for cache size 4096\t: 0.12024335105234958\n",
      "Mean squared error for cache size 8192\t: 0.1049763171270845\n",
      "Epoch 1/2\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.0191\n",
      "Epoch 2/2\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0174\n",
      "Mean squared error for cache size 1024\t: 0.0336328169726877\n",
      "Mean squared error for cache size 2048\t: 0.10282340739916572\n",
      "Mean squared error for cache size 4096\t: 0.12545416123334907\n",
      "Mean squared error for cache size 8192\t: 0.11836617647336607\n",
      "Epoch 1/2\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.0157\n",
      "Epoch 2/2\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0142\n",
      "Mean squared error for cache size 1024\t: 0.04504434609413935\n",
      "Mean squared error for cache size 2048\t: 0.1198942653319735\n",
      "Mean squared error for cache size 4096\t: 0.15867369751834334\n",
      "Mean squared error for cache size 8192\t: 0.14611066574176726\n",
      "Epoch 1/2\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.0140\n",
      "Epoch 2/2\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.0124\n",
      "Mean squared error for cache size 1024\t: 0.032947373916792436\n",
      "Mean squared error for cache size 2048\t: 0.1236943170148029\n",
      "Mean squared error for cache size 4096\t: 0.14615912088180796\n",
      "Mean squared error for cache size 8192\t: 0.13468786402821092\n",
      "Epoch 1/2\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.0133\n",
      "Epoch 2/2\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.0122\n",
      "Mean squared error for cache size 1024\t: 0.04123707217706804\n",
      "Mean squared error for cache size 2048\t: 0.13490501078837197\n",
      "Mean squared error for cache size 4096\t: 0.1547315732873022\n",
      "Mean squared error for cache size 8192\t: 0.14517494143209997\n",
      "Epoch 1/2\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.0130\n",
      "Epoch 2/2\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.0135\n",
      "Mean squared error for cache size 1024\t: 0.03771900051918921\n",
      "Mean squared error for cache size 2048\t: 0.12325811440360282\n",
      "Mean squared error for cache size 4096\t: 0.13280074875207537\n",
      "Mean squared error for cache size 8192\t: 0.12505698173832827\n",
      "Epoch 1/2\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.0124\n",
      "Epoch 2/2\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.0115\n",
      "Mean squared error for cache size 1024\t: 0.039114094241299975\n",
      "Mean squared error for cache size 2048\t: 0.13153109687825185\n",
      "Mean squared error for cache size 4096\t: 0.14257092171525945\n",
      "Mean squared error for cache size 8192\t: 0.14521809034354338\n",
      "Epoch 1/2\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.0128\n",
      "Epoch 2/2\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.0120\n",
      "Mean squared error for cache size 1024\t: 0.033581490629238396\n",
      "Mean squared error for cache size 2048\t: 0.13202876783766984\n",
      "Mean squared error for cache size 4096\t: 0.14926009808550733\n",
      "Mean squared error for cache size 8192\t: 0.15113294179068518\n"
     ]
    }
   ],
   "source": [
    "j = ['1024', '2048', '4096', '8192']\n",
    "m = dnn_model([896,896,len(j)])\n",
    "m.summary()\n",
    "#for i,k in enumerate(j):\n",
    "#   print(mean_squared_error(m(train_rds.to_numpy())[:,i], train_mrs[k].to_numpy()))\n",
    "for i in range(10):\n",
    "    m.fit(train_rds.to_numpy(), train_mrs[j].to_numpy(), epochs=2)\n",
    "#    for i,k in enumerate(j):\n",
    "#        print(mean_squared_error(m(train_rds.to_numpy())[:,i], train_mrs[k].to_numpy()))\n",
    "    for i,k in enumerate(j):\n",
    "        print(f'Mean squared error for cache size {k}\\t: {mean_squared_error(m(test_rds.to_numpy())[:,i], test_mrs[k].to_numpy())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c93e175",
   "metadata": {},
   "source": [
    "# Mockinjay replacement Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "294b20ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test set consists of 56 files (out of 189) with a total of 1696 rows (out of 6182)\n"
     ]
    }
   ],
   "source": [
    "rds, mrs = read_df('../ce_data/output_512/dataset_mj.csv')\n",
    "# print(rds, mrs)\n",
    "train_rds, train_mrs, test_rds, test_mrs = train_test_split(rds, mrs, split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da542304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 896)               803712    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 896)               803712    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 4)                 3588      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,611,012\n",
      "Trainable params: 1,611,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 0.0553\n",
      "Epoch 2/2\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.0443\n",
      "Mean squared error for cache size 1024\t: 0.11806458191745896\n",
      "Mean squared error for cache size 2048\t: 0.07942598515408282\n",
      "Mean squared error for cache size 4096\t: 0.12202709388801564\n",
      "Mean squared error for cache size 8192\t: 0.14402506094936754\n",
      "Epoch 1/2\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.0438\n",
      "Epoch 2/2\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.0408\n",
      "Mean squared error for cache size 1024\t: 0.1174517339782126\n",
      "Mean squared error for cache size 2048\t: 0.080582255846707\n",
      "Mean squared error for cache size 4096\t: 0.1007350439299447\n",
      "Mean squared error for cache size 8192\t: 0.11029243567383748\n",
      "Epoch 1/2\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.0252\n",
      "Epoch 2/2\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.0177\n",
      "Mean squared error for cache size 1024\t: 0.054653540776791\n",
      "Mean squared error for cache size 2048\t: 0.073357778235896\n",
      "Mean squared error for cache size 4096\t: 0.09649920150648705\n",
      "Mean squared error for cache size 8192\t: 0.10268470121102163\n",
      "Epoch 1/2\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.0169\n",
      "Epoch 2/2\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.0142\n",
      "Mean squared error for cache size 1024\t: 0.0641990856561554\n",
      "Mean squared error for cache size 2048\t: 0.07546133028176269\n",
      "Mean squared error for cache size 4096\t: 0.09064173238890098\n",
      "Mean squared error for cache size 8192\t: 0.0907622444352678\n",
      "Epoch 1/2\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 0.0124\n",
      "Epoch 2/2\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.0127\n",
      "Mean squared error for cache size 1024\t: 0.06204203326868789\n",
      "Mean squared error for cache size 2048\t: 0.07525665096921688\n",
      "Mean squared error for cache size 4096\t: 0.08842611721785065\n",
      "Mean squared error for cache size 8192\t: 0.08394567057110851\n",
      "Epoch 1/2\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 0.0122\n",
      "Epoch 2/2\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 0.0118\n",
      "Mean squared error for cache size 1024\t: 0.06626588343324732\n",
      "Mean squared error for cache size 2048\t: 0.07674811094627572\n",
      "Mean squared error for cache size 4096\t: 0.09066282267522302\n",
      "Mean squared error for cache size 8192\t: 0.08571978904353705\n",
      "Epoch 1/2\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 0.0116\n",
      "Epoch 2/2\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 0.0104\n",
      "Mean squared error for cache size 1024\t: 0.0597105710945094\n",
      "Mean squared error for cache size 2048\t: 0.07327331647061465\n",
      "Mean squared error for cache size 4096\t: 0.08755468971149577\n",
      "Mean squared error for cache size 8192\t: 0.08475823256660231\n",
      "Epoch 1/2\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 0.0105\n",
      "Epoch 2/2\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 0.0105\n",
      "Mean squared error for cache size 1024\t: 0.05958670465806559\n",
      "Mean squared error for cache size 2048\t: 0.07123886167164808\n",
      "Mean squared error for cache size 4096\t: 0.08263964188290349\n",
      "Mean squared error for cache size 8192\t: 0.0823918393084104\n",
      "Epoch 1/2\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 0.0100\n",
      "Epoch 2/2\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 0.0097\n",
      "Mean squared error for cache size 1024\t: 0.06288612175827707\n",
      "Mean squared error for cache size 2048\t: 0.07610599294250618\n",
      "Mean squared error for cache size 4096\t: 0.08611781498511632\n",
      "Mean squared error for cache size 8192\t: 0.0829091398546736\n",
      "Epoch 1/2\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 0.0094\n",
      "Epoch 2/2\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 0.0094\n",
      "Mean squared error for cache size 1024\t: 0.06157728906398957\n",
      "Mean squared error for cache size 2048\t: 0.07438006200654024\n",
      "Mean squared error for cache size 4096\t: 0.08323393007470294\n",
      "Mean squared error for cache size 8192\t: 0.08224837851085486\n"
     ]
    }
   ],
   "source": [
    "j = ['1024', '2048', '4096', '8192']\n",
    "m = dnn_model([896,896,len(j)])\n",
    "m.summary()\n",
    "#for i,k in enumerate(j):\n",
    "#   print(mean_squared_error(m(train_rds.to_numpy())[:,i], train_mrs[k].to_numpy()))\n",
    "for i in range(10):\n",
    "    m.fit(train_rds.to_numpy(), train_mrs[j].to_numpy(), epochs=2)\n",
    "#    for i,k in enumerate(j):\n",
    "#        print(mean_squared_error(m(train_rds.to_numpy())[:,i], train_mrs[k].to_numpy()))\n",
    "    for i,k in enumerate(j):\n",
    "        print(f'Mean squared error for cache size {k}\\t: {mean_squared_error(m(test_rds.to_numpy())[:,i], test_mrs[k].to_numpy())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3e4a4d",
   "metadata": {},
   "source": [
    "# Srrip replacement Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d9b6590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test set consists of 48 files (out of 189) with a total of 1593 rows (out of 6181)\n"
     ]
    }
   ],
   "source": [
    "rds, mrs = read_df('../ce_data/output_512/dataset_srrip.csv')\n",
    "# print(rds, mrs)\n",
    "train_rds, train_mrs, test_rds, test_mrs = train_test_split(rds, mrs, split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04fb8885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 896)               803712    \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 896)               803712    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4)                 3588      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,611,012\n",
      "Trainable params: 1,611,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "144/144 [==============================] - 2s 9ms/step - loss: 0.0563\n",
      "Epoch 2/2\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0382\n",
      "Mean squared error for cache size 1024\t: 0.015242504870059473\n",
      "Mean squared error for cache size 2048\t: 0.05618234474675598\n",
      "Mean squared error for cache size 4096\t: 0.0998030073370528\n",
      "Mean squared error for cache size 8192\t: 0.1304343437360494\n",
      "Epoch 1/2\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0269\n",
      "Epoch 2/2\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0234\n",
      "Mean squared error for cache size 1024\t: 0.009689949587370425\n",
      "Mean squared error for cache size 2048\t: 0.023108800415725064\n",
      "Mean squared error for cache size 4096\t: 0.039773745917993035\n",
      "Mean squared error for cache size 8192\t: 0.05467871441242901\n",
      "Epoch 1/2\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0202\n",
      "Epoch 2/2\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0185\n",
      "Mean squared error for cache size 1024\t: 0.018599133358244202\n",
      "Mean squared error for cache size 2048\t: 0.03629979386427819\n",
      "Mean squared error for cache size 4096\t: 0.08208393346894935\n",
      "Mean squared error for cache size 8192\t: 0.08257876272843762\n",
      "Epoch 1/2\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 2/2\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0150\n",
      "Mean squared error for cache size 1024\t: 0.009223170158679423\n",
      "Mean squared error for cache size 2048\t: 0.02314858245235951\n",
      "Mean squared error for cache size 4096\t: 0.025269744963403448\n",
      "Mean squared error for cache size 8192\t: 0.06160743723796535\n",
      "Epoch 1/2\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0150\n",
      "Epoch 2/2\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0131\n",
      "Mean squared error for cache size 1024\t: 0.007501486002114996\n",
      "Mean squared error for cache size 2048\t: 0.017410100488005526\n",
      "Mean squared error for cache size 4096\t: 0.030869088865374657\n",
      "Mean squared error for cache size 8192\t: 0.05296324829220912\n",
      "Epoch 1/2\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0131\n",
      "Epoch 2/2\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0142\n",
      "Mean squared error for cache size 1024\t: 0.007854796830049346\n",
      "Mean squared error for cache size 2048\t: 0.014539679542735754\n",
      "Mean squared error for cache size 4096\t: 0.03257303819643829\n",
      "Mean squared error for cache size 8192\t: 0.06448350330539404\n",
      "Epoch 1/2\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0113\n",
      "Epoch 2/2\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0127\n",
      "Mean squared error for cache size 1024\t: 0.007327911938770631\n",
      "Mean squared error for cache size 2048\t: 0.014723285604621649\n",
      "Mean squared error for cache size 4096\t: 0.027279756486766667\n",
      "Mean squared error for cache size 8192\t: 0.04981252838701552\n",
      "Epoch 1/2\n",
      "144/144 [==============================] - 1s 10ms/step - loss: 0.0106\n",
      "Epoch 2/2\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0100\n",
      "Mean squared error for cache size 1024\t: 0.006559902546870735\n",
      "Mean squared error for cache size 2048\t: 0.013774056002070696\n",
      "Mean squared error for cache size 4096\t: 0.0380296326904302\n",
      "Mean squared error for cache size 8192\t: 0.056433145614427194\n",
      "Epoch 1/2\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0106\n",
      "Epoch 2/2\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0100\n",
      "Mean squared error for cache size 1024\t: 0.007229724577011069\n",
      "Mean squared error for cache size 2048\t: 0.018088973110816295\n",
      "Mean squared error for cache size 4096\t: 0.05757726094944463\n",
      "Mean squared error for cache size 8192\t: 0.0812388075635283\n",
      "Epoch 1/2\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0103\n",
      "Epoch 2/2\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0090\n",
      "Mean squared error for cache size 1024\t: 0.007944708256106632\n",
      "Mean squared error for cache size 2048\t: 0.017348676405588948\n",
      "Mean squared error for cache size 4096\t: 0.04650261475423866\n",
      "Mean squared error for cache size 8192\t: 0.07226371212424311\n"
     ]
    }
   ],
   "source": [
    "j = ['1024', '2048', '4096', '8192']\n",
    "m = dnn_model([896,896,len(j)])\n",
    "m.summary()\n",
    "#for i,k in enumerate(j):\n",
    "#   print(mean_squared_error(m(train_rds.to_numpy())[:,i], train_mrs[k].to_numpy()))\n",
    "for i in range(10):\n",
    "    m.fit(train_rds.to_numpy(), train_mrs[j].to_numpy(), epochs=2)\n",
    "#    for i,k in enumerate(j):\n",
    "#        print(mean_squared_error(m(train_rds.to_numpy())[:,i], train_mrs[k].to_numpy()))\n",
    "    for i,k in enumerate(j):\n",
    "        print(f'Mean squared error for cache size {k}\\t: {mean_squared_error(m(test_rds.to_numpy())[:,i], test_mrs[k].to_numpy())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d55124",
   "metadata": {},
   "source": [
    "## ~~ ~~ LSTM ~~ ~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "858f2480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test set consists of 30 files (out of 189) with a total of 1611 rows (out of 6183)\n"
     ]
    }
   ],
   "source": [
    "rds, mrs = read_df('../ce_data/output_512/dataset_lru.csv')\n",
    "# print(rds, mrs)\n",
    "train_rds, train_mrs, test_rds, test_mrs = train_test_split(rds, mrs, split=0.25)\n",
    "output_columns = ['1024', '2048']\n",
    "train_rds = train_rds.to_numpy()\n",
    "train_mrs = train_mrs[output_columns].to_numpy()\n",
    "test_rds = test_rds.to_numpy()\n",
    "test_mrs = test_mrs[output_columns].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0f9860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_d, hidden_d, layer_d, output_d):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.hidden = None\n",
    "        \n",
    "        self.hidden_dim = hidden_d\n",
    "        self.layer_dim = layer_d\n",
    "\n",
    "        # LSTM model \n",
    "        self.lstm = nn.LSTM(input_d, hidden_d, layer_d, batch_first=True) \n",
    "\n",
    "        self.fc = nn.Linear(hidden_d, output_d)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42cac697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4572, 896) (4572, 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3846634a908047429088cdc7a2be4368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=71)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, torch\u001b[38;5;241m.\u001b[39mTensor(y_batch)\u001b[38;5;241m.\u001b[39mview(X_batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;28mlen\u001b[39m(output_columns)))\n\u001b[0;32m     31\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 32\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     34\u001b[0m f\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\Compilers\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Compilers\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "input_dim = 1\n",
    "hidden_dim = 32\n",
    "output_dim = len(output_columns)\n",
    "layer_dim = 16\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "loader = data.DataLoader(data.TensorDataset(torch.Tensor(train_rds), torch.Tensor(train_mrs)), shuffle=True, batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
    "loss_fn = nn.MSELoss()\n",
    "print(train_rds.shape, train_mrs.shape)\n",
    "n_epochs = 2000\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    f = IntProgress(min=0, max=train_rds.shape[0]//batch_size) # instantiate the bar\n",
    "    display(f) # display the bar\n",
    "\n",
    "    for X_batch, y_batch in loader:\n",
    "        f.value += 1 # signal to increment the progress bar\n",
    "        y_pred = model(torch.Tensor(X_batch).view(X_batch.shape[0],896, 1))\n",
    "        loss = loss_fn(y_pred, torch.Tensor(y_batch).view(X_batch.shape[0],len(output_columns)))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    f.close()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(torch.Tensor(train_rds).view(train_rds.shape[0], 896, 1))\n",
    "        train_rmse = np.sqrt(loss_fn(y_pred, torch.Tensor(train_mrs)))\n",
    "        y_pred = model(torch.Tensor(test_rds).view(test_rds.shape[0], 896, 1))\n",
    "        test_rmse = np.sqrt(loss_fn(y_pred, torch.Tensor(test_mrs)))\n",
    "    print(\"Epoch %d: train RMSE %.4f, test RMSE %.4f\" % (epoch, train_rmse, test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbaf13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cc5dd7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1920325409812926662\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d4e04b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
